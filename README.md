# 智能RAG对话助手系统

基于LangChain和大语言模型构建的本地知识库问答系统，支持多模态交互、多智能体角色扮演和记忆管理。

## 项目介绍

本项目是一个基于检索增强生成(RAG)技术的智能对话系统，支持文档知识库构建、多轮对话、语音交互和角色扮演等功能。系统使用本地部署的Ollama模型作为大语言模型后端，可根据不同场景灵活切换智能体角色。

## 功能特点

- **多模态交互**：支持文本和语音双模态输入输出
- **知识库管理**：支持PDF、Word和TXT等多种格式文档导入
- **多角色智能体**：支持创建不同角色的AI智能体(如语文老师、数学老师等)
- **对话记忆管理**：具备上下文记忆和记忆刷新功能
- **自动角色路由**：能根据问题内容自动分配到适合的智能体
- **流式输出**：支持大语言模型的流式文本生成，提升用户体验
- **会话管理**：可保存、恢复、删除多个会话

## 技术架构

- **前端**：HTML/CSS/JavaScript，提供直观的Web界面
- **后端**：Flask Web框架，提供API接口和服务
- **对话引擎**：基于LangChain构建的RAG对话系统
- **语音处理**：集成语音识别(STT)和语音合成(TTS)功能
- **向量数据库**：使用FAISS进行高效相似度搜索
- **嵌入模型**：使用DashScope API的文本嵌入服务
- **大语言模型**：使用本地部署的Ollama模型(如QWen 2.5)

## 项目结构

```
.
├── app.py                 # 主应用服务器(Flask)
├── rag_core.py            # RAG核心逻辑实现
├── speech_to_text.py      # 语音识别功能
├── text_to_speech.py      # 语音合成功能
├── run.py                 # 应用启动脚本
├── requirements.txt       # 项目依赖
├── knowledge_base/        # 示例知识库文档
├── templates/             # HTML模板
│   └── index.html         # 主页面模板
├── static/                # 静态资源文件
│   ├── style.css          # 样式表
│   └── script.js          # 前端JavaScript脚本
├── agents/                # 智能体配置文件存储
├── conversations/         # 对话历史记录存储
├── uploads/               # 上传文件临时存储
├── vector_stores/         # 向量数据库存储
└── MEMORY_OPTIMIZATION_README.md  # 记忆优化说明文档
```

## 安装与部署

### 前提条件

1. Python 3.8+ 环境
2. [Ollama](https://ollama.ai/) 本地部署
3. DashScope API密钥(用于文本嵌入)

### 安装步骤

1. 克隆项目代码：
   ```bash
   git clone <项目仓库URL>
   cd <项目目录>
   ```

2. 安装依赖包：
   ```bash
   pip install -r requirements.txt
   ```

3. 设置环境变量(可选，也可在代码中直接设置)：
   ```bash
   export DASHSCOPE_API_KEY="您的DashScope API密钥"
   ```

4. 安装并运行Ollama服务：
   - 访问[Ollama官网](https://ollama.ai/)下载并安装
   - 拉取模型(以QWen 2.5为例)：
     ```bash
     ollama pull qwen2.5:3b
     ```

5. 启动应用：
   ```bash
   python run.py
   ```
   
6. 访问Web界面：
   - 打开浏览器访问 http://localhost:5001

## 使用说明

### 创建智能体

1. 点击"新建对话"按钮
2. 选择"创建新智能体"选项卡
3. 填写智能体名称、类型(通用/语文老师/数学老师等)和角色描述
4. 上传知识库文件(支持PDF、DOCX、TXT格式)
5. 点击"创建并开始对话"

### 与智能体对话

1. 在对话框中输入问题并发送
2. 系统会根据知识库内容和上下文生成回答
3. 支持点击语音按钮进行语音输入
4. 可开启语音通话模式，实现全程语音交互

### 会话管理

- 在左侧会话列表可查看和切换历史会话
- 可对会话进行重命名和删除操作
- 使用"刷新记忆"按钮更新对话上下文
- 使用"记忆状态"查看当前对话的记忆情况

### 智能体管理

- 可创建多个不同角色的智能体
- 每个智能体可关联不同的知识库
- 系统会根据问题内容自动选择合适的智能体进行回答

## 高级功能

### 记忆优化

系统采用对话记忆优化技术，可有效管理长对话中的上下文信息，详见`MEMORY_OPTIMIZATION_README.md`。

### 多轮对话

支持复杂的多轮对话，系统会根据上下文生成连贯的回复。

### 语音交互

支持全双工语音通话模式，可实现类似电话交谈的自然交互体验。

## 常见问题

1. **如何更换大语言模型?**
   - 修改`rag_core.py`中的模型配置，使用Ollama支持的其他模型

2. **如何增加自定义知识库?**
   - 直接通过Web界面上传文档到指定智能体

3. **如何调整生成文本的长度和质量?**
   - 可调整`rag_core.py`中的温度(temperature)参数

4. **如何解决向量存储问题?**
   - 通常由文件权限或磁盘空间不足导致，请检查相关目录权限

## 开发与扩展

### 添加新智能体类型

在`app.py`中的`AGENT_TYPES`字典添加新的智能体类型定义。

### 自定义提示词模板

修改`rag_core.py`中的提示词模板可自定义对话生成风格。

### 添加新文档类型支持

在`rag_core.py`的`load_documents`函数中添加新的文档加载器。

## 许可证

[适用的开源许可证] 